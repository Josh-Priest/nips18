[File Names]
# Directory that files are stored in, will replace all %(directory)s in the following lines
directory = ./iris

nodes = %(directory)s/nodesIris.csv
hashtags = %(directory)s/tagIris.csv
communities = %(directory)s/comIris.csv
user_hashtag_matrix = %(directory)s/StructuralUserHashtagIris2.csv

[Parameters]

# Solver options are "CBC" (COIN-OR Branch-&-Cut) and "GRB" (Gurobi), recommended Gurobi
solver = GRB
# Optimization time is an integer number of seconds
optimization_time = 60
# write_model_file is true if a file detailing the objective and constraints should be generated
write_model_file = true
# if true, the filename for the above file should be specified. If above line is false, this does nothing
model_filename = model.lp

# Delete users with posts less than following number
minimum_post_count = 0
# Delete users using a number of unique tags less than the following number
minimum_unique_tags = 0
# Minimum times a tag can be used to describe a cluster
minimum_overlap = 1

# Cover_or_forget = true if that formulation should be run
cover_or_forget = false
# The following parameter should be a list of k numbers (equal to the number of clusters)
# separated by ", " exactly. Each number specifices how many nodes can be forgotten in cluster 1, 2, ..., k.
number_to_forget_for_each_cluster =
    20, 20, 20, 20, 20

# apart_constraint = true if a list of hashtags that should never be assigned to the same cluster is provided
apart_constraint = true
# The following parameter should have the format of "hashtag, apart_tag, apart_tag..., apart_tag"
# Each apart tag listed is only specified to be separated from the first tag in the list.
# Each constraint should be separated by new lines
apart =
    small sepal length, average sepal length, large sepal length
    average sepal length, large sepal length, small sepal length
    large sepal length, small sepal length, average sepal length
    small sepal width, average sepal width, large sepal width
    average sepal width, large sepal width, small sepal width
    large sepal width, small sepal width, average sepal width
    small petal length, average petal length, large petal length
    average petal length, large petal length, small petal length
    large petal length, small petal length, average petal length
    small petal width, average petal width, large petal width
    average petal width, large petal width, small petal width
    large petal width, small petal width, average petal width


# together_constraint = true if a list of tags that should be combined is provided
# note: this can be done in the data providing stage as well
together_constraint = false
# Each hashtag following the first in each line is combined with the first hashtag in each line.
# For example, "Trump, trump, TRUMP, DonaldTrump" would add
# all usages of "trump", "TRUMP", and "DonaldTrump" to the tag "Trump"
# and then remove those three from the list of tags.
# each constraint should be separated by new lines.
together =
    Trump, trump, TRUMP, DonaldTrump
    Clinton, ImWithHer, Hillary, HillaryClinton
    GOPdebate, GOPDebate

use_maximal_itemsets = false
maximal_itemsets =
